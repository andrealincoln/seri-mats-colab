{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfpdIS5MW-l5"
      },
      "source": [
        "# Andrea and Adam colab\n",
        "\n",
        "<b style=\"color: red\">To use this notebook, go to Runtime > Change Runtime Type and select GPU as the hardware accelerator.</b>\n",
        "\n",
        "This notebook is based on (https://colab.research.google.com/github/neelnanda-io/TransformerLens/blob/main/demos/Exploratory_Analysis_Demo.ipynb\n",
        ")\n",
        "\n",
        "and\n",
        "\n",
        "https://colab.research.google.com/github/neelnanda-io/Easy-Transformer/blob/clean-transformer-demo/Clean_Transformer_Demo.ipynb#scrollTo=Jlse3dAHjHcw\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDkbMAKdW-l7"
      },
      "source": [
        "# Setup\n",
        "(No need to read)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "v6ikJELuW-l7",
        "outputId": "05530575-6fdd-4b44-9743-423b675cff0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running as a Colab notebook\n",
            "Collecting git+https://github.com/neelnanda-io/TransformerLens.git\n",
            "  Cloning https://github.com/neelnanda-io/TransformerLens.git to /tmp/pip-req-build-rflpih21\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/neelnanda-io/TransformerLens.git /tmp/pip-req-build-rflpih21\n",
            "  Resolved https://github.com/neelnanda-io/TransformerLens.git to commit 3cd943628b5c415585c8ef100f65989f6adc7f75\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: datasets>=2.7.1 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (2.13.1)\n",
            "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (0.6.1)\n",
            "Requirement already satisfied: fancy-einsum>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (0.0.3)\n",
            "Requirement already satisfied: jaxtyping>=0.2.11 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (0.2.20)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (1.25.0)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (1.5.3)\n",
            "Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (13.4.2)\n",
            "Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (4.65.0)\n",
            "Requirement already satisfied: transformers>=4.25.1 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (4.30.2)\n",
            "Collecting typeguard<4.0.0,>=3.0.2 (from transformer-lens==0.0.0)\n",
            "  Using cached typeguard-3.0.2-py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: wandb>=0.13.5 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (0.15.4)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (0.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (2.27.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (3.2.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (3.8.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (0.15.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.10/dist-packages (from jaxtyping>=0.2.11->transformer-lens==0.0.0) (4.6.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer-lens==0.0.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer-lens==0.0.0) (2022.7.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer-lens==0.0.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer-lens==0.0.0) (2.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (3.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10->transformer-lens==0.0.0) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10->transformer-lens==0.0.0) (16.0.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->transformer-lens==0.0.0) (2022.10.31)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->transformer-lens==0.0.0) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->transformer-lens==0.0.0) (0.3.1)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (8.1.3)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (3.1.31)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (1.26.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (0.4.0)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (0.1.2)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (1.3.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.13.5->transformer-lens==0.0.0) (1.16.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.3.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens==0.0.0) (4.0.10)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer-lens==0.0.0) (0.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10->transformer-lens==0.0.0) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10->transformer-lens==0.0.0) (1.3.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens==0.0.0) (5.0.0)\n",
            "Installing collected packages: typeguard\n",
            "  Attempting uninstall: typeguard\n",
            "    Found existing installation: typeguard 2.13.3\n",
            "    Uninstalling typeguard-2.13.3:\n",
            "      Successfully uninstalled typeguard-2.13.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pysvelte 1.0.0 requires typeguard~=2.0, but you have typeguard 3.0.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed typeguard-3.0.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "typeguard"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "## Installing the NodeSource Node.js 16.x repo...\n",
            "\n",
            "\n",
            "## Populating apt-get cache...\n",
            "\n",
            "+ apt-get update\n",
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "\r            \rHit:2 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.91.38)] [1 InRelease 22.9 kB/114 k\r                                                                               \rHit:3 https://deb.nodesource.com/node_16.x focal InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.91.38)] [1 InRelease 43.1 kB/114 k\r                                                                               \rHit:4 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.91.38)] [1 InRelease 53.3 kB/114 k\r                                                                               \rHit:5 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.91.38)] [1 InRelease 57.6 kB/114 k\r0% [Connecting to archive.ubuntu.com (91.189.91.38)] [Waiting for headers] [Wai\r                                                                               \rHit:6 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.91.38)] [Connecting to ppa.launchp\r                                                                               \rHit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "\r                                                                               \r0% [Connecting to archive.ubuntu.com (91.189.91.38)] [Waiting for headers]\r                                                                          \rHit:8 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Hit:9 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Fetched 336 kB in 31s (10.9 kB/s)\n",
            "Reading package lists... Done\n",
            "\n",
            "## Confirming \"focal\" is supported...\n",
            "\n",
            "+ curl -sLf -o /dev/null 'https://deb.nodesource.com/node_16.x/dists/focal/Release'\n",
            "\n",
            "## Adding the NodeSource signing key to your keyring...\n",
            "\n",
            "+ curl -s https://deb.nodesource.com/gpgkey/nodesource.gpg.key | gpg --dearmor | tee /usr/share/keyrings/nodesource.gpg >/dev/null\n",
            "\n",
            "## Creating apt sources list file for the NodeSource Node.js 16.x repo...\n",
            "\n",
            "+ echo 'deb [signed-by=/usr/share/keyrings/nodesource.gpg] https://deb.nodesource.com/node_16.x focal main' > /etc/apt/sources.list.d/nodesource.list\n",
            "+ echo 'deb-src [signed-by=/usr/share/keyrings/nodesource.gpg] https://deb.nodesource.com/node_16.x focal main' >> /etc/apt/sources.list.d/nodesource.list\n",
            "\n",
            "## Running `apt-get update` for you...\n",
            "\n",
            "+ apt-get update\n",
            "Hit:1 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Hit:3 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu focal-updates InRelease\n",
            "Hit:5 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Hit:7 https://deb.nodesource.com/node_16.x focal InRelease\n",
            "Hit:8 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Hit:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "Hit:10 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Hit:11 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Hit:12 http://security.ubuntu.com/ubuntu focal-security InRelease\n",
            "Fetched 108 kB in 30s (3,587 B/s)\n",
            "Reading package lists... Done\n",
            "\n",
            "## Run `\u001b[1msudo apt-get install -y nodejs\u001b[m` to install Node.js 16.x and npm\n",
            "## You may also need development tools to build native addons:\n",
            "     sudo apt-get install gcc g++ make\n",
            "## To install the Yarn package manager, run:\n",
            "     curl -sL https://dl.yarnpkg.com/debian/pubkey.gpg | gpg --dearmor | sudo tee /usr/share/keyrings/yarnkey.gpg >/dev/null\n",
            "     echo \"deb [signed-by=/usr/share/keyrings/yarnkey.gpg] https://dl.yarnpkg.com/debian stable main\" | sudo tee /etc/apt/sources.list.d/yarn.list\n",
            "     sudo apt-get update && sudo apt-get install yarn\n",
            "\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "nodejs is already the newest version (16.20.1-deb-1nodesource1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 20 not upgraded.\n",
            "Collecting git+https://github.com/neelnanda-io/PySvelte.git\n",
            "  Cloning https://github.com/neelnanda-io/PySvelte.git to /tmp/pip-req-build-ul7v4fzb\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/neelnanda-io/PySvelte.git /tmp/pip-req-build-ul7v4fzb\n",
            "  Resolved https://github.com/neelnanda-io/PySvelte.git to commit 6f5d971a148d40fb7481d400ae74551b37340e83\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from PySvelte==1.0.0) (0.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from PySvelte==1.0.0) (1.25.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from PySvelte==1.0.0) (2.0.1+cu118)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from PySvelte==1.0.0) (2.13.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from PySvelte==1.0.0) (4.30.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from PySvelte==1.0.0) (4.65.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from PySvelte==1.0.0) (1.5.3)\n",
            "Collecting typeguard~=2.0 (from PySvelte==1.0.0)\n",
            "  Using cached typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (0.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (2.27.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (3.2.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (3.8.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (0.15.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->PySvelte==1.0.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->PySvelte==1.0.0) (2022.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->PySvelte==1.0.0) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->PySvelte==1.0.0) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->PySvelte==1.0.0) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->PySvelte==1.0.0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->PySvelte==1.0.0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->PySvelte==1.0.0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->PySvelte==1.0.0) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->PySvelte==1.0.0) (16.0.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->PySvelte==1.0.0) (2022.10.31)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers->PySvelte==1.0.0) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers->PySvelte==1.0.0) (0.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (1.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->PySvelte==1.0.0) (1.16.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->PySvelte==1.0.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->PySvelte==1.0.0) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->PySvelte==1.0.0) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->PySvelte==1.0.0) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->PySvelte==1.0.0) (1.3.0)\n",
            "Installing collected packages: typeguard\n",
            "  Attempting uninstall: typeguard\n",
            "    Found existing installation: typeguard 3.0.2\n",
            "    Uninstalling typeguard-3.0.2:\n",
            "      Successfully uninstalled typeguard-3.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "transformer-lens 0.0.0 requires typeguard<4.0.0,>=3.0.2, but you have typeguard 2.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed typeguard-2.13.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "typeguard"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/neelnanda-io/Easy-Transformer.git@clean-transformer-demo\n",
            "  Cloning https://github.com/neelnanda-io/Easy-Transformer.git (to revision clean-transformer-demo) to /tmp/pip-req-build-t46qnim1\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/neelnanda-io/Easy-Transformer.git /tmp/pip-req-build-t46qnim1\n",
            "  Running command git checkout -b clean-transformer-demo --track origin/clean-transformer-demo\n",
            "  Switched to a new branch 'clean-transformer-demo'\n",
            "  Branch 'clean-transformer-demo' set up to track remote branch 'clean-transformer-demo' from 'origin'.\n",
            "  Resolved https://github.com/neelnanda-io/Easy-Transformer.git to commit 1f25219e631aeb478d17075d47274db32c874e88\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from easy-transformer==0.1.0) (0.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from easy-transformer==0.1.0) (1.25.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from easy-transformer==0.1.0) (2.0.1+cu118)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from easy-transformer==0.1.0) (2.13.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from easy-transformer==0.1.0) (4.30.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from easy-transformer==0.1.0) (4.65.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from easy-transformer==0.1.0) (1.5.3)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (from easy-transformer==0.1.0) (0.15.4)\n",
            "Requirement already satisfied: fancy_einsum in /usr/local/lib/python3.10/dist-packages (from easy-transformer==0.1.0) (0.0.3)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->easy-transformer==0.1.0) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->easy-transformer==0.1.0) (0.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets->easy-transformer==0.1.0) (2.27.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->easy-transformer==0.1.0) (3.2.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->easy-transformer==0.1.0) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets->easy-transformer==0.1.0) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->easy-transformer==0.1.0) (3.8.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets->easy-transformer==0.1.0) (0.15.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets->easy-transformer==0.1.0) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->easy-transformer==0.1.0) (6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->easy-transformer==0.1.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->easy-transformer==0.1.0) (2022.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->easy-transformer==0.1.0) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->easy-transformer==0.1.0) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->easy-transformer==0.1.0) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->easy-transformer==0.1.0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->easy-transformer==0.1.0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->easy-transformer==0.1.0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->easy-transformer==0.1.0) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->easy-transformer==0.1.0) (16.0.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->easy-transformer==0.1.0) (2022.10.31)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers->easy-transformer==0.1.0) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers->easy-transformer==0.1.0) (0.3.1)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.10/dist-packages (from wandb->easy-transformer==0.1.0) (8.1.3)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->easy-transformer==0.1.0) (3.1.31)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->easy-transformer==0.1.0) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->easy-transformer==0.1.0) (1.26.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb->easy-transformer==0.1.0) (0.4.0)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.10/dist-packages (from wandb->easy-transformer==0.1.0) (0.1.2)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb->easy-transformer==0.1.0) (1.3.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb->easy-transformer==0.1.0) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb->easy-transformer==0.1.0) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb->easy-transformer==0.1.0) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb->easy-transformer==0.1.0) (1.16.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->easy-transformer==0.1.0) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->easy-transformer==0.1.0) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->easy-transformer==0.1.0) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->easy-transformer==0.1.0) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->easy-transformer==0.1.0) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->easy-transformer==0.1.0) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->easy-transformer==0.1.0) (1.3.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb->easy-transformer==0.1.0) (4.0.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->easy-transformer==0.1.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->easy-transformer==0.1.0) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->easy-transformer==0.1.0) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->easy-transformer==0.1.0) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->easy-transformer==0.1.0) (1.3.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->easy-transformer==0.1.0) (5.0.0)\n",
            "\n",
            "## Installing the NodeSource Node.js 16.x repo...\n",
            "\n",
            "\n",
            "## Populating apt-get cache...\n",
            "\n",
            "+ apt-get update\n",
            "Hit:1 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Hit:3 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu focal-updates InRelease\n",
            "Hit:5 https://deb.nodesource.com/node_16.x focal InRelease\n",
            "Hit:6 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Get:7 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Hit:8 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Hit:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "Hit:10 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Hit:11 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Hit:12 http://security.ubuntu.com/ubuntu focal-security InRelease\n",
            "Fetched 108 kB in 30s (3,591 B/s)\n",
            "Reading package lists... Done\n",
            "\n",
            "## Confirming \"focal\" is supported...\n",
            "\n",
            "+ curl -sLf -o /dev/null 'https://deb.nodesource.com/node_16.x/dists/focal/Release'\n",
            "\n",
            "## Adding the NodeSource signing key to your keyring...\n",
            "\n",
            "+ curl -s https://deb.nodesource.com/gpgkey/nodesource.gpg.key | gpg --dearmor | tee /usr/share/keyrings/nodesource.gpg >/dev/null\n",
            "\n",
            "## Creating apt sources list file for the NodeSource Node.js 16.x repo...\n",
            "\n",
            "+ echo 'deb [signed-by=/usr/share/keyrings/nodesource.gpg] https://deb.nodesource.com/node_16.x focal main' > /etc/apt/sources.list.d/nodesource.list\n",
            "+ echo 'deb-src [signed-by=/usr/share/keyrings/nodesource.gpg] https://deb.nodesource.com/node_16.x focal main' >> /etc/apt/sources.list.d/nodesource.list\n",
            "\n",
            "## Running `apt-get update` for you...\n",
            "\n",
            "+ apt-get update\n",
            "Hit:1 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Hit:4 https://deb.nodesource.com/node_16.x focal InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu focal-updates InRelease\n",
            "Hit:6 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Get:7 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Hit:8 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Hit:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "Hit:10 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Hit:11 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Get:12 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "Fetched 222 kB in 30s (7,315 B/s)\n",
            "Reading package lists... Done\n",
            "\n",
            "## Run `\u001b[1msudo apt-get install -y nodejs\u001b[m` to install Node.js 16.x and npm\n",
            "## You may also need development tools to build native addons:\n",
            "     sudo apt-get install gcc g++ make\n",
            "## To install the Yarn package manager, run:\n",
            "     curl -sL https://dl.yarnpkg.com/debian/pubkey.gpg | gpg --dearmor | sudo tee /usr/share/keyrings/yarnkey.gpg >/dev/null\n",
            "     echo \"deb [signed-by=/usr/share/keyrings/yarnkey.gpg] https://dl.yarnpkg.com/debian stable main\" | sudo tee /etc/apt/sources.list.d/yarn.list\n",
            "     sudo apt-get update && sudo apt-get install yarn\n",
            "\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "nodejs is already the newest version (16.20.1-deb-1nodesource1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 20 not upgraded.\n",
            "Collecting git+https://github.com/neelnanda-io/PySvelte.git\n",
            "  Cloning https://github.com/neelnanda-io/PySvelte.git to /tmp/pip-req-build-mzgj1cjt\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/neelnanda-io/PySvelte.git /tmp/pip-req-build-mzgj1cjt\n",
            "  Resolved https://github.com/neelnanda-io/PySvelte.git to commit 6f5d971a148d40fb7481d400ae74551b37340e83\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from PySvelte==1.0.0) (0.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from PySvelte==1.0.0) (1.25.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from PySvelte==1.0.0) (2.0.1+cu118)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from PySvelte==1.0.0) (2.13.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from PySvelte==1.0.0) (4.30.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from PySvelte==1.0.0) (4.65.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from PySvelte==1.0.0) (1.5.3)\n",
            "Requirement already satisfied: typeguard~=2.0 in /usr/local/lib/python3.10/dist-packages (from PySvelte==1.0.0) (2.13.3)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (0.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (2.27.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (3.2.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (3.8.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (0.15.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->PySvelte==1.0.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->PySvelte==1.0.0) (2022.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->PySvelte==1.0.0) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->PySvelte==1.0.0) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->PySvelte==1.0.0) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->PySvelte==1.0.0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->PySvelte==1.0.0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->PySvelte==1.0.0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->PySvelte==1.0.0) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->PySvelte==1.0.0) (16.0.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->PySvelte==1.0.0) (2022.10.31)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers->PySvelte==1.0.0) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers->PySvelte==1.0.0) (0.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (1.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->PySvelte==1.0.0) (1.16.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->PySvelte==1.0.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->PySvelte==1.0.0) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->PySvelte==1.0.0) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->PySvelte==1.0.0) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->PySvelte==1.0.0) (1.3.0)\n",
            "Requirement already satisfied: fancy_einsum in /usr/local/lib/python3.10/dist-packages (0.0.3)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.6.1)\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2022.10.31)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.4.0\n"
          ]
        }
      ],
      "source": [
        "# Janky code to do different setup when run in a Colab notebook vs VSCode\n",
        "DEBUG_MODE = False\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"Running as a Colab notebook\")\n",
        "    %pip install git+https://github.com/neelnanda-io/TransformerLens.git\n",
        "    # Install another version of node that makes PySvelte work way faster\n",
        "    !curl -fsSL https://deb.nodesource.com/setup_16.x | sudo -E bash -; sudo apt-get install -y nodejs\n",
        "    %pip install git+https://github.com/neelnanda-io/PySvelte.git\n",
        "    %pip install git+https://github.com/neelnanda-io/Easy-Transformer.git@clean-transformer-demo\n",
        "    # Install another version of node that makes PySvelte work way faster\n",
        "    !curl -fsSL https://deb.nodesource.com/setup_16.x | sudo -E bash -; sudo apt-get install -y nodejs\n",
        "    %pip install git+https://github.com/neelnanda-io/PySvelte.git\n",
        "    %pip install fancy_einsum\n",
        "    %pip install einops\n",
        "    %pip install tiktoken\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    print(\"Running as a Jupyter notebook - intended for development only!\")\n",
        "    from IPython import get_ipython\n",
        "\n",
        "    ipython = get_ipython()\n",
        "    # Code to automatically update the TransformerLens code as its edited without restarting the kernel\n",
        "    ipython.magic(\"load_ext autoreload\")\n",
        "    ipython.magic(\"autoreload 2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "t6i4msOkW-l8"
      },
      "outputs": [],
      "source": [
        "# Plotly needs a different renderer for VSCode/Notebooks vs Colab argh\n",
        "import plotly.io as pio\n",
        "\n",
        "if IN_COLAB or not DEBUG_MODE:\n",
        "    # Thanks to annoying rendering issues, Plotly graphics will either show up in colab OR Vscode depending on the renderer - this is bad for developing demos! Thus creating a debug mode.\n",
        "    pio.renderers.default = \"colab\"\n",
        "else:\n",
        "    pio.renderers.default = \"png\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4aZ-R0KKW-l8"
      },
      "outputs": [],
      "source": [
        "# Import stuff\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import einops\n",
        "from fancy_einsum import einsum\n",
        "import tqdm.notebook as tqdm\n",
        "import random\n",
        "from pathlib import Path\n",
        "import plotly.express as px\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from jaxtyping import Float, Int\n",
        "from typing import List, Union, Optional\n",
        "from functools import partial\n",
        "import copy\n",
        "\n",
        "import itertools\n",
        "from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n",
        "import dataclasses\n",
        "import datasets\n",
        "from IPython.display import HTML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "d7kZsjgtW-l9"
      },
      "outputs": [],
      "source": [
        "import pysvelte\n",
        "\n",
        "import transformer_lens\n",
        "import transformer_lens.utils as utils\n",
        "from transformer_lens.hook_points import (\n",
        "    HookedRootModule,\n",
        "    HookPoint,\n",
        ")  # Hooking utilities\n",
        "from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ps6glfBVW-l9"
      },
      "source": [
        "We turn automatic differentiation off, to save GPU memory, as this notebook focuses on model inference not model training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rlMCRwJaW-l9",
        "outputId": "98db7648-9679-4e4b-f778-022c2d1dcf5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.autograd.grad_mode.set_grad_enabled at 0x7fbd30300070>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "torch.set_grad_enabled(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZg1MPU1W-l9"
      },
      "source": [
        "Plotting helper functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "TODteIMCW-l-"
      },
      "outputs": [],
      "source": [
        "def imshow(tensor, renderer=None, **kwargs):\n",
        "    px.imshow(utils.to_numpy(tensor), color_continuous_midpoint=0.0, color_continuous_scale=\"RdBu\", **kwargs).show(renderer)\n",
        "\n",
        "def line(tensor, renderer=None, **kwargs):\n",
        "    px.line(y=utils.to_numpy(tensor), **kwargs).show(renderer)\n",
        "\n",
        "def scatter(x, y, xaxis=\"\", yaxis=\"\", caxis=\"\", renderer=None, **kwargs):\n",
        "    x = utils.to_numpy(x)\n",
        "    y = utils.to_numpy(y)\n",
        "    px.scatter(y=y, x=x, labels={\"x\":xaxis, \"y\":yaxis, \"color\":caxis}, **kwargs).show(renderer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "uAvlaglBW-l-",
        "outputId": "bbb53b9d-0643-4ea5-89dc-abfe60c5de35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245,
          "referenced_widgets": [
            "a84e4b105f7240c683f831cb49020a56",
            "d89e5aa9b9494acf8e62d12cdb1cddea",
            "c28a33e923ab4fbb863bd76e9517fccb",
            "2f1f75b982814d7497316b47e0fa537d",
            "d3e721d768494315b9dc2fa1268d6b45",
            "0be8731903a64845a63ff46f54e065c6",
            "1897b1ff2ba84e69905f40f9c47cafe7",
            "7e37eb8309d54502a3d7169e30501e5a",
            "0752b803614445c2970371992930d85d",
            "794172797dc543fbbe4536d8b849fbf6",
            "7da2c357e1b74ebf80abf19471269d12",
            "e7e55462b5eb4da0b9babab9a18727bf",
            "2c39eff701764f1199f2a6a2e676edcf",
            "c5eeccdae2cb4e9394eec4545faa9571",
            "fd9b7e79adf94b1fa518e97747d67180",
            "46037b01da29484eb019b7771387611d",
            "54c16adb46304a55baf9ac87368cf598",
            "1b1ebc1f9cf5486ca3f86a4a8fba1ef9",
            "6aee52c665ed418d8af75fabd9c80434",
            "b81b83c3670d4a8698a8a1daa056a7e9",
            "b44ae51aadf54ada8a47b6bc76828e48",
            "7e1cf1fe90bf401d96ca4c0da4c35cd4",
            "3ee89d75315041d2890d0179210101cc",
            "aef7fc32abea4b598c3bbdc530524c1d",
            "2bb742f2b01a482d823e5b8769c9f853",
            "954aca4c5b014c749b63e75cd9c215c0",
            "5266a7eeb57244d081d180eb58db8017",
            "8d45b2f6294c450aa8fabdda1eaf82ad",
            "4119255fd7ea4662aed35ab1ae7d5272",
            "97ec2c35f4ef4cfcb77a2465dd9e8828",
            "0297bcaaefbb4f58bdabd171bc0749d8",
            "e18eb8e96d214325b37c6bdee56b41fe",
            "14f6bdf701dc4099a911b41ea707b3c6",
            "d3bc6578e54f40cea1516b51b5afec64",
            "6c03fc86cdca48eb98a293b472e8465b",
            "5059f5bef2ec4c00b798ceaa3c94d3c8",
            "a22c234ed2aa44c79e5888079598b7d8",
            "9a182cc64a2d4f24b7e0643db120383b",
            "d564c82253854017bfc2f9d416c61bf3",
            "fc9e72c7580d4526af5288fbd4d4069f",
            "f045d93988d84766a3e430a9988d954d",
            "57758202d2a04157a331ec629e6ec9e3",
            "3ca35e387c85459b9f841e7fd3015a33",
            "ffe93005711e4820a3e79b0f41fe243d",
            "fb0839d3abce489fb4baabda852584da",
            "cee525e248b54f06ab89e2863bb117d0",
            "44c36481157f4cd6890f496b6e059e9f",
            "5729560342e546d48bcde49ad8d0569f",
            "84c1001000f943c2b32abd280e686204",
            "8b9e091bb46b415dba916ecf20e1850c",
            "18268faf2748435da147f71eb1555316",
            "2e7eaa0c21714867857d7eb90c47976c",
            "cfe52ec68cfb46d89fde26f3c2fc45ca",
            "5fb4482c5837496caf72c008a78a15e0",
            "98ff50465e054ac29ee08e02a527dbea",
            "e3b0ba3dece840a19770d8e2b78d6123",
            "04ebdc3fcdb74e8bbaf63024d8e4ae14",
            "0eaa83c6a62648a0b6d5d8a9c61d5e58",
            "c06fa45bfcf94c52a47a6252b9fee05f",
            "23428c96d9e34f0ea75d06fbefd2a41e",
            "a4d9b74c63c84474a1900b4690868b8b",
            "54aed3ddaec441f6905d12cb5fc1770a",
            "2a52bb728d4c4dbc8d843868fd50d6a9",
            "4242ea29288d4664a77f8a8ef4fa7095",
            "1d3a91a94c5c4005b71f24c8e9684b97",
            "ec3d86915cbf44ccba658b5b789ae9ff"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a84e4b105f7240c683f831cb49020a56"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e7e55462b5eb4da0b9babab9a18727bf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3ee89d75315041d2890d0179210101cc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d3bc6578e54f40cea1516b51b5afec64"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fb0839d3abce489fb4baabda852584da"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e3b0ba3dece840a19770d8e2b78d6123"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using pad_token, but it is not set yet.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained model gpt2-small into HookedTransformer\n"
          ]
        }
      ],
      "source": [
        "model = HookedTransformer.from_pretrained(\n",
        "    \"gpt2-small\",\n",
        "    center_unembed=True,\n",
        "    center_writing_weights=True,\n",
        "    fold_ln=True,\n",
        "    refactor_factored_attn_matrices=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test that the imports are working by running this**"
      ],
      "metadata": {
        "id": "u-atQpuhbO2O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "zMM2CtDsW-l-",
        "outputId": "22897063-cfc5-4e0e-f2e8-fe8c00212a7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized prompt: ['<|endoftext|>', 'After', ' John', ' and', ' Mary', ' went', ' to', ' the', ' store', ',', ' John', ' gave', ' a', ' bottle', ' of', ' milk', ' to']\n",
            "Tokenized answer: [' Mary']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Performance on answer token:\n",
              "\u001b[1mRank: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m18.09\u001b[0m\u001b[1m Prob: \u001b[0m\u001b[1;36m70.07\u001b[0m\u001b[1m% Token: | Mary|\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
              "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18.09</span><span style=\"font-weight: bold\"> Prob: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">70.07</span><span style=\"font-weight: bold\">% Token: | Mary|</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 0th token. Logit: 18.09 Prob: 70.07% Token: | Mary|\n",
            "Top 1th token. Logit: 15.38 Prob:  4.67% Token: | the|\n",
            "Top 2th token. Logit: 15.35 Prob:  4.54% Token: | John|\n",
            "Top 3th token. Logit: 15.25 Prob:  4.11% Token: | them|\n",
            "Top 4th token. Logit: 14.84 Prob:  2.73% Token: | his|\n",
            "Top 5th token. Logit: 14.06 Prob:  1.24% Token: | her|\n",
            "Top 6th token. Logit: 13.54 Prob:  0.74% Token: | a|\n",
            "Top 7th token. Logit: 13.52 Prob:  0.73% Token: | their|\n",
            "Top 8th token. Logit: 13.13 Prob:  0.49% Token: | Jesus|\n",
            "Top 9th token. Logit: 12.97 Prob:  0.42% Token: | him|\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' Mary'\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' Mary'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "example_prompt = \"After John and Mary went to the store, John gave a bottle of milk to\"\n",
        "example_answer = \" Mary\"\n",
        "utils.test_prompt(example_prompt, example_answer, model, prepend_bos=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Our Code"
      ],
      "metadata": {
        "id": "ng2T-w6jbxSV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import pickle\n",
        "import einops\n",
        "from fancy_einsum import einsum\n",
        "from transformer_lens import HookedTransformer\n",
        "from transformer_lens import loading_from_pretrained as loading\n",
        "from transformer_lens.utils import gelu_new\n",
        "from dataclasses import dataclass\n",
        "from collections import namedtuple\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import tqdm.auto as tqdm\n",
        "import matplotlib.lines as mlines\n",
        "import heapq\n",
        "from typing import NamedTuple"
      ],
      "metadata": {
        "id": "dtFEja0gb39j"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IN_COLAB = True\n",
        "M1_MAC = False\n",
        "\n",
        "import pickle\n",
        "import einops\n",
        "from fancy_einsum import einsum\n",
        "from transformer_lens import HookedTransformer\n",
        "from transformer_lens import loading_from_pretrained as loading\n",
        "from transformer_lens.utils import gelu_new\n",
        "from dataclasses import dataclass\n",
        "from collections import namedtuple\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.lines as mlines\n",
        "import tiktoken\n",
        "import IPython\n",
        "\n",
        "\n",
        "TITLE_TOKEN_INDEXES = [1583,  1770, 9074, 6997, 6187, 5246, 27034, 10128]\n",
        "\n",
        "enc = tiktoken.get_encoding('r50k_base')\n",
        "\n",
        "model_name = \"gpt2-small\"\n",
        "\n",
        "\n",
        "def cuda(x):\n",
        "    return x.to('cpu') if M1_MAC else x.cuda()\n",
        "\n",
        "\n",
        "reference_gpt2 = HookedTransformer.from_pretrained(model_name, fold_ln=False, center_unembed=False,\n",
        "                                                   center_writing_weights=False)\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Config:\n",
        "    d_model: int = 768\n",
        "    debug: bool = False\n",
        "    layer_norm_eps: float = 1e-5\n",
        "    d_vocab: int = 50257\n",
        "    init_range: float = 0.02\n",
        "    n_ctx: int = 1024\n",
        "    d_head: int = 64\n",
        "    d_mlp: int = 3072\n",
        "    n_heads: int = 12\n",
        "    n_layers: int = 12\n",
        "\n",
        "\n",
        "def get_basic_config(model_name: str, **kwargs) -> Config:\n",
        "    return Config(\n",
        "        **{k: v for k, v in loading.get_pretrained_model_config(model_name,\n",
        "                                                                **kwargs).to_dict().items() if k in [\n",
        "               'd_model',\n",
        "               'layer_norm_eps',\n",
        "               'd_vocab',\n",
        "               'init_range',\n",
        "               'n_ctx',\n",
        "               'd_head',\n",
        "               'd_mlp',\n",
        "               'n_heads',\n",
        "               'n_layers',\n",
        "           ]})\n",
        "\n",
        "\n",
        "cfg = get_basic_config(model_name)\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.w = nn.Parameter(torch.ones(cfg.d_model))\n",
        "        self.b = nn.Parameter(torch.zeros(cfg.d_model))\n",
        "\n",
        "    def forward(self, residual):\n",
        "        # residual: [batch, position, d_model]\n",
        "        if self.cfg.debug: print(\"Residual:\", residual.shape)\n",
        "        residual = residual - einops.reduce(residual, \"batch position d_model -> batch position 1\", \"mean\")\n",
        "        # Calculate the variance, square root it. Add in an epsilon to prevent divide by zero.\n",
        "        scale = (einops.reduce(residual.pow(2), \"batch position d_model -> batch position 1\",\n",
        "                               \"mean\") + cfg.layer_norm_eps).sqrt()\n",
        "        normalized = residual / scale\n",
        "        normalized = normalized * self.w + self.b\n",
        "        if self.cfg.debug: print(\"Normalized:\", residual.shape)\n",
        "        return normalized\n",
        "\n",
        "\n",
        "class Embed(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.W_E = nn.Parameter(torch.empty((cfg.d_vocab, cfg.d_model)))\n",
        "        nn.init.normal_(self.W_E, std=self.cfg.init_range)\n",
        "\n",
        "    def forward(self, tokens):\n",
        "        # tokens: [batch, position]\n",
        "        if self.cfg.debug: print(\"Tokens:\", tokens.shape)\n",
        "        embed = self.W_E[tokens, :]  # [batch, position, d_model]\n",
        "        # visualize_tensor(self.W_E, 'WE')\n",
        "        if self.cfg.debug: print(\"Embeddings:\", embed.shape)\n",
        "        return embed\n",
        "\n",
        "\n",
        "\n",
        "class PosEmbed(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.W_pos = nn.Parameter(torch.empty((cfg.n_ctx, cfg.d_model)))\n",
        "        nn.init.normal_(self.W_pos, std=self.cfg.init_range)\n",
        "\n",
        "    def forward(self, tokens):\n",
        "        # tokens: [batch, position]\n",
        "        if self.cfg.debug: print(\"Tokens:\", tokens.shape)\n",
        "        pos_embed = self.W_pos[:tokens.size(1), :]  # [position, d_model]\n",
        "        pos_embed = einops.repeat(pos_embed, \"position d_model -> batch position d_model\", batch=tokens.size(0))\n",
        "        if self.cfg.debug: print(\"pos_embed:\", pos_embed.shape)\n",
        "        return pos_embed\n",
        "\n",
        "\n",
        "class OblationInstruction:\n",
        "    def __init__(self, layer, head_number):\n",
        "        self.layer = layer\n",
        "        self.head_number = head_number\n",
        "\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, cfg, index, ):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.W_Q = nn.Parameter(torch.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
        "        nn.init.normal_(self.W_Q, std=self.cfg.init_range)\n",
        "        self.b_Q = nn.Parameter(torch.zeros((cfg.n_heads, cfg.d_head)))\n",
        "        self.W_K = nn.Parameter(torch.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
        "        nn.init.normal_(self.W_K, std=self.cfg.init_range)\n",
        "        self.b_K = nn.Parameter(torch.zeros((cfg.n_heads, cfg.d_head)))\n",
        "        self.W_V = nn.Parameter(torch.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
        "        nn.init.normal_(self.W_V, std=self.cfg.init_range)\n",
        "        self.b_V = nn.Parameter(torch.zeros((cfg.n_heads, cfg.d_head)))\n",
        "\n",
        "        self.W_O = nn.Parameter(torch.empty((cfg.n_heads, cfg.d_head, cfg.d_model)))\n",
        "        nn.init.normal_(self.W_O, std=self.cfg.init_range)\n",
        "        self.b_O = nn.Parameter(torch.zeros((cfg.d_model)))\n",
        "\n",
        "        self.register_buffer(\"IGNORE\", torch.tensor(-1e5, dtype=torch.float32, device=\"cpu\" if M1_MAC else \"cuda\"))\n",
        "        self.index = index\n",
        "\n",
        "    def forward(self, normalized_resid_pre, oblation_instruction=None):\n",
        "        # normalized_resid_pre: [batch, position, d_model]\n",
        "        if self.cfg.debug: print(\"Normalized_resid_pre:\", normalized_resid_pre.shape)\n",
        "\n",
        "        q = einsum(\"batch query_pos d_model, n_heads d_model d_head -> batch query_pos n_heads d_head\",\n",
        "                   normalized_resid_pre, self.W_Q) + self.b_Q\n",
        "        k = einsum(\"batch key_pos d_model, n_heads d_model d_head -> batch key_pos n_heads d_head\",\n",
        "                   normalized_resid_pre, self.W_K) + self.b_K\n",
        "\n",
        "        attn_scores = einsum(\n",
        "            \"batch query_pos n_heads d_head, batch key_pos n_heads d_head -> batch n_heads query_pos key_pos\", q, k)\n",
        "        attn_scores = attn_scores / math.sqrt(self.cfg.d_head)\n",
        "\n",
        "        attn_scores = self.apply_causal_mask(attn_scores)\n",
        "        pattern = attn_scores.softmax(dim=-1)  # [batch, n_head, query_pos, key_pos]\n",
        "\n",
        "        # if we are instructing oblation then oblate at that layer and head number\n",
        "        if oblation_instruction:\n",
        "            o_i = oblation_instruction\n",
        "            layer = o_i.layer\n",
        "            head_number = o_i.head_number\n",
        "            if self.index == layer:\n",
        "                for row in range(pattern[0][head_number].shape[0]):\n",
        "                    for column in range(pattern[0][head_number].shape[1]):\n",
        "                        pattern[0][head_number][row][column] = 0.0\n",
        "\n",
        "        v = einsum(\"batch key_pos d_model, n_heads d_model d_head -> batch key_pos n_heads d_head\",\n",
        "                   normalized_resid_pre, self.W_V) + self.b_V\n",
        "\n",
        "        z = einsum(\"batch n_heads query_pos key_pos, batch key_pos n_heads d_head -> batch query_pos n_heads d_head\",\n",
        "                   pattern, v)\n",
        "\n",
        "        attn_out = einsum(\"batch query_pos n_heads d_head, n_heads d_head d_model -> batch query_pos d_model\", z,\n",
        "                          self.W_O) + self.b_O\n",
        "\n",
        "        return attn_out\n",
        "\n",
        "    def apply_causal_mask(self, attn_scores):\n",
        "        # attn_scores: [batch, n_heads, query_pos, key_pos]\n",
        "        mask = torch.triu(torch.ones(attn_scores.size(-2), attn_scores.size(-1), device=attn_scores.device),\n",
        "                          diagonal=1).bool()\n",
        "        attn_scores.masked_fill_(mask, self.IGNORE)\n",
        "        return attn_scores\n",
        "\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.W_in = nn.Parameter(torch.empty((cfg.d_model, cfg.d_mlp)))\n",
        "        nn.init.normal_(self.W_in, std=self.cfg.init_range)\n",
        "        self.b_in = nn.Parameter(torch.zeros((cfg.d_mlp)))\n",
        "        self.W_out = nn.Parameter(torch.empty((cfg.d_mlp, cfg.d_model)))\n",
        "        nn.init.normal_(self.W_out, std=self.cfg.init_range)\n",
        "        self.b_out = nn.Parameter(torch.zeros((cfg.d_model)))\n",
        "\n",
        "    def forward(self, normalized_resid_mid):\n",
        "        # normalized_resid_mid: [batch, position, d_model]\n",
        "        if self.cfg.debug: print(\"Normalized_resid_mid:\", normalized_resid_mid.shape)\n",
        "        pre = einsum(\"batch position d_model, d_model d_mlp -> batch position d_mlp\", normalized_resid_mid,\n",
        "                     self.W_in) + self.b_in\n",
        "        post = gelu_new(pre)\n",
        "        mlp_out = einsum(\"batch position d_mlp, d_mlp d_model -> batch position d_model\", post, self.W_out) + self.b_out\n",
        "        return mlp_out\n",
        "\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg, i):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "\n",
        "        self.ln1 = LayerNorm(cfg)\n",
        "        self.attn = Attention(cfg, i)\n",
        "        self.ln2 = LayerNorm(cfg)\n",
        "        self.mlp = MLP(cfg)\n",
        "        self.index = i\n",
        "\n",
        "    def forward(self, resid_pre, o_i=None):\n",
        "        # resid_pre [batch, position, d_model]\n",
        "        normalized_resid_pre = self.ln1(resid_pre)\n",
        "        attn_out = self.attn(normalized_resid_pre,  oblation_instruction=o_i)\n",
        "        resid_mid = resid_pre + attn_out\n",
        "\n",
        "        normalized_resid_mid = self.ln2(resid_mid)\n",
        "        mlp_out = self.mlp(normalized_resid_mid)\n",
        "        resid_post = resid_mid + mlp_out\n",
        "        return resid_post\n",
        "\n",
        "\n",
        "class Unembed(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.W_U = nn.Parameter(torch.empty((cfg.d_model, cfg.d_vocab)))\n",
        "        nn.init.normal_(self.W_U, std=self.cfg.init_range)\n",
        "        self.b_U = nn.Parameter(torch.zeros((cfg.d_vocab), requires_grad=False))\n",
        "\n",
        "    def forward(self, normalized_resid_final):\n",
        "        # normalized_resid_final [batch, position, d_model]\n",
        "        if self.cfg.debug: print(\"Normalized_resid_final:\", normalized_resid_final.shape)\n",
        "        logits = einsum(\"batch position d_model, d_model d_vocab -> batch position d_vocab\", normalized_resid_final,\n",
        "                        self.W_U) + self.b_U\n",
        "        return logits\n",
        "\n",
        "\n",
        "SaveTokensAtPeriodInfo = namedtuple('SaveTokensAtPeriodInfo',['filename', 'end_indexes', 'middle_indexes'])\n",
        "\n",
        "class DemoTransformer(nn.Module):\n",
        "    def __init__(self, cfg,):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.embed = Embed(cfg)\n",
        "        self.pos_embed = PosEmbed(cfg)\n",
        "        self.blocks = nn.ModuleList([TransformerBlock(cfg, i) for i in range(cfg.n_layers)])\n",
        "        self.ln_final = LayerNorm(cfg)\n",
        "        self.unembed = Unembed(cfg)\n",
        "\n",
        "    def forward(self, tokens, save_with_prefix=None, load=False, load_with_mod_vector=None,\n",
        "                intervene_in_resid_at_layer=None, resid_intervention_filename=None, save_tokens_at_index=None,\n",
        "                split_tokens_by_lists=None, split_tokens_by_lists_filename=None, reflect_vector_info=None,\n",
        "                o_i=None, index_lists_with_output_lists=None, store_index_diffs=None,\n",
        "                replace_layer_i_with_title_intervention=None, pca_intervention_layer_and_index_list=None):\n",
        "        # tokens [batch, position]\n",
        "\n",
        "        if load:\n",
        "            residual = pickle.load(open('resid.p', 'rb'))\n",
        "\n",
        "            plt.plot(residual.detach().numpy().flatten())\n",
        "            # plt.show()\n",
        "\n",
        "            if load_with_mod_vector is not None:\n",
        "                residual = residual + load_with_mod_vector\n",
        "        else:\n",
        "            embed = self.embed(tokens)\n",
        "            pos_embed = self.pos_embed(tokens)\n",
        "            residual = embed + pos_embed\n",
        "            start_residual = embed + pos_embed\n",
        "            if intervene_in_resid_at_layer == 'start' and resid_intervention_filename:\n",
        "                residual_intervention = pickle.load(open(resid_intervention_filename, 'rb'))\n",
        "                residual = (residual + torch.from_numpy(residual_intervention)).float()\n",
        "            if save_with_prefix:\n",
        "                pickle.dump(residual, open(f'resid_{save_with_prefix}_start.p', 'wb'))\n",
        "                pickle.dump(embed, open(f'resid_{save_with_prefix}_embed.p', 'wb'))\n",
        "                pickle.dump(pos_embed, open(f'resid_{save_with_prefix}_pos_embed.p', 'wb'))\n",
        "            if index_lists_with_output_lists:\n",
        "                for index_list, dict_list_by_layer in index_lists_with_output_lists:\n",
        "                    for index in index_list:\n",
        "                        if store_index_diffs:\n",
        "                            dict_list_by_layer['start'].append(residual[0][index] - start_residual[0][index])\n",
        "                        else:\n",
        "                            dict_list_by_layer['start'].append(residual[0][index])\n",
        "\n",
        "        for i, block in enumerate(self.blocks):\n",
        "            residual = block(residual, o_i)\n",
        "            if pca_intervention_layer_and_index_list:\n",
        "                layer = pca_intervention_layer_and_index_list['layer']\n",
        "                if i == layer:\n",
        "                    index_list = pca_intervention_layer_and_index_list['index_list']\n",
        "                    if len(index_list) > 0:\n",
        "                        size_of_residual = torch.norm(residual).item()\n",
        "                        multiplier = pca_intervention_layer_and_index_list['multiplier']\n",
        "                        # if we want an intervention that is multiplier of the size of residual\n",
        "                        print(size_of_residual)\n",
        "                        per_index_multiplier = multiplier * size_of_residual / len(index_list)\n",
        "                        component_number = pca_intervention_layer_and_index_list['component_number']\n",
        "                        is_absolute = pca_intervention_layer_and_index_list['is_absolute']\n",
        "                        pca_vector = torch.from_numpy(\n",
        "                            (per_index_multiplier * get_pca_vector(\n",
        "                                layer, component_number, is_absolute=is_absolute\n",
        "                            ))\n",
        "                        )\n",
        "                        for index in index_list:\n",
        "                            residual[0][index] = (residual[0][index] + pca_vector).float()\n",
        "\n",
        "                        print(f'Size of residual at start: {size_of_residual}')\n",
        "                        size_of_intervention = torch.norm(pca_vector) * len(index_list)\n",
        "                        print(f'Size of intervention: {size_of_intervention}')\n",
        "                        print(f'Size of residual after intervention: {torch.norm(residual)}')\n",
        "                        percent = 100 * size_of_intervention / size_of_residual\n",
        "                        print(f'Percent {percent} %')\n",
        "            if replace_layer_i_with_title_intervention and i == replace_layer_i_with_title_intervention:\n",
        "                my_intervention_dict = pickle.load(open('title_intervention_dict.p', 'rb'))\n",
        "                # find indexes which need to be overwritten. We are looking for a .\n",
        "                # proceded by a title_token_index\n",
        "                for title_token_index in TITLE_TOKEN_INDEXES:\n",
        "                    for j in range(len(tokens[0])-1):\n",
        "                        if (tokens[0][j].item() == title_token_index) and (tokens[0][j+1] == 13):\n",
        "                            period_token = j+1\n",
        "                            residual[0][period_token] = start_residual[0][period_token] + my_intervention_dict[title_token_index][i]\n",
        "\n",
        "            if reflect_vector_info and i == reflect_vector_info['layer']:\n",
        "                cls = reflect_vector_info['cls']\n",
        "                token_index = reflect_vector_info['token_index']\n",
        "                token_as_np_array = residual[0][token_index].detach().numpy()\n",
        "                resid_at_start = residual.clone()\n",
        "                new_resid_for_token = reflect_vector(token_as_np_array, cls)\n",
        "                for j in range(len(residual[0][token_index])):\n",
        "                    residual[0][token_index][j] = new_resid_for_token[0][j]\n",
        "\n",
        "                print(f'Size of residual at start: {torch.norm(resid_at_start)}')\n",
        "                print(f'Size of intervention: {torch.norm(residual- resid_at_start)}')\n",
        "                size_of_intervention = torch.norm(residual - resid_at_start)\n",
        "                print(f'Size of residual after intervention: {torch.norm(residual)}')\n",
        "                percent = 100* size_of_intervention/torch.norm(resid_at_start)\n",
        "                print(f'Percent {percent} %')\n",
        "                array_for_size_percent = reflect_vector_info['array_for_size_percent']\n",
        "                array_for_size_percent.append((i, percent))\n",
        "            if i == intervene_in_resid_at_layer and resid_intervention_filename:\n",
        "                residual_intervention = pickle.load(open(resid_intervention_filename, 'rb'))\n",
        "                print('intervening!')\n",
        "                print(sum(sum(sum(residual))))\n",
        "                residual = (residual + torch.from_numpy(residual_intervention)).float()\n",
        "                print(sum(sum(sum(residual))))\n",
        "            if save_with_prefix:\n",
        "                pickle.dump(residual, open(f'resid_{save_with_prefix}_{i}.p', 'wb'))\n",
        "            if save_tokens_at_index:\n",
        "                filename = save_tokens_at_index.filename\n",
        "                end_indexes = save_tokens_at_index.end_indexes\n",
        "                end_tokens_list = pickle.load(open(f'ends_{filename}_{i}.p', 'rb'))\n",
        "                for index in end_indexes:\n",
        "                    end_tokens_list.append(residual[0][index])\n",
        "                    # print(f'len end ={len(end_tokens_list)}')\n",
        "                pickle.dump(end_tokens_list, open(f'ends_{filename}_{i}.p', 'wb'))\n",
        "\n",
        "                middle_indexes = save_tokens_at_index.middle_indexes\n",
        "                middle_tokens_list = pickle.load(open(f'middles_{filename}_{i}.p', 'rb'))\n",
        "                for index in middle_indexes:\n",
        "                    middle_tokens_list.append(residual[0][index])\n",
        "                    # print(f'len middle ={len(middle_tokens_list)}')\n",
        "                pickle.dump(middle_tokens_list, open(f'middles_{filename}_{i}.p', 'wb'))\n",
        "            # print(residual)\n",
        "            if split_tokens_by_lists and split_tokens_by_lists_filename:\n",
        "                my_filename = split_tokens_by_lists_filename\n",
        "                for key, index_list in split_tokens_by_lists.items():\n",
        "                    current_token_list = pickle.load(open(f'{my_filename}_{key}_{i}.p', 'rb'))\n",
        "                    for index in index_list:\n",
        "                        current_token_list.append(residual[0][index])\n",
        "                    pickle.dump(current_token_list, open(f'{my_filename}_{key}_{i}.p', 'wb'))\n",
        "            if index_lists_with_output_lists:\n",
        "\n",
        "                for index_list, dict_list_by_layer in index_lists_with_output_lists:\n",
        "                    for index in index_list:\n",
        "                        if store_index_diffs:\n",
        "                            dict_list_by_layer[i].append(residual[0][index] - start_residual[0][index])\n",
        "                        else:\n",
        "                            dict_list_by_layer[i].append(residual[0][index])\n",
        "\n",
        "        normalized_resid_final = self.ln_final(residual)\n",
        "\n",
        "        logits = self.unembed(normalized_resid_final)\n",
        "        return logits\n",
        "\n",
        "\n",
        "demo_gpt2 = DemoTransformer(get_basic_config(model_name=model_name))\n",
        "demo_gpt2.load_state_dict(reference_gpt2.state_dict(), strict=False)\n",
        "\n",
        "\n",
        "def print_top_n_last_token_from_logits(my_logits, n, compare_on_these_token_indices):\n",
        "    # Get the logits for the last predicted token\n",
        "    last_logits = my_logits[-1, -1]\n",
        "    # Apply softmax to convert the logits to probabilities\n",
        "    probabilities = torch.nn.functional.softmax(last_logits, dim=0).detach().numpy()\n",
        "\n",
        "    # Get the indices of the top n probabilities\n",
        "    topk_indices = np.argpartition(probabilities, -n)[-n:]\n",
        "    # Get the top n probabilities\n",
        "    topk_probabilities = probabilities[topk_indices]\n",
        "    # Get the top n tokens\n",
        "    topk_tokens = [reference_gpt2.tokenizer.decode(i) for i in topk_indices]\n",
        "\n",
        "    prob_token_list = list(zip(topk_probabilities, topk_tokens))\n",
        "    prob_token_list.sort()\n",
        "    # Print the top n tokens and their probabilities\n",
        "    for probability, token in prob_token_list:\n",
        "        print(f\"Token: \\\"{token}\\\", Probability: {probability}\")\n",
        "    if compare_on_these_token_indices:\n",
        "        return [probabilities[index] for index in compare_on_these_token_indices]\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def run_gpt2_small_on_string(input_string, prefix, o_i=None, print_logits=False):\n",
        "    test_tokens_in = cuda(reference_gpt2.to_tokens(input_string))\n",
        "    # is enc.encode('?.!') [30, 13, 0]\n",
        "    end_of_sentence_tokens = [30, 13, 0]\n",
        "    end_of_sentence_indicies = [ind for ind, ele in enumerate(test_tokens_in[0]) if ele.item() in end_of_sentence_tokens]\n",
        "    demo_logits_def = demo_gpt2(test_tokens_in, save_with_prefix=prefix, o_i=o_i)\n",
        "    if print_logits:\n",
        "        print_top_n_last_token_from_logits(demo_logits_def, 5, None)\n",
        "    return end_of_sentence_indicies\n",
        "\n",
        "\n",
        "\n",
        "# Run a test to see how the classifier works\n",
        "def run_a_test_against_clf_layer_i(string, file_name, layer, cls_file_name, prediction_interpreter=None):\n",
        "    clf = pickle.load(open(f'cls_{cls_file_name}_{layer}.p', 'rb'))\n",
        "    run_gpt2_small_on_string(string, file_name)\n",
        "    x = pickle.load(open(f'resid_{file_name}_{layer}.p', 'rb'))\n",
        "    token_vecs = [t.detach().numpy() for t in x[0]]\n",
        "    set_1 = np.vstack(token_vecs)\n",
        "    predictions = clf.predict(set_1)\n",
        "    if prediction_interpreter:\n",
        "        predictions = [prediction_interpreter[prediction] for prediction in predictions]\n",
        "    tokens_1 = [enc.decode([j]) for j in cuda(reference_gpt2.to_tokens(string))[0]]\n",
        "    return [(a, b) for a, b in zip(tokens_1, predictions)]\n",
        "\n",
        "\n",
        "def demo_of_subject_end_of_sentence_other(sentence, layer):\n",
        "    test_string = \"test_andrea\"\n",
        "    file_name = \"split_token_by_lists_test_subject\"\n",
        "    return run_a_test_against_clf_layer_i(\n",
        "        sentence, test_string, layer, file_name,\n",
        "        prediction_interpreter={\n",
        "            0: \"Subject\",\n",
        "            1: \"Other\",\n",
        "            2:\"End of Sentence\"\n",
        "        }\n",
        "    )\n",
        "\n",
        "\n",
        "def oblate_and_run_a_test_against_clf_layer_i(string, file_name, i, cls_file_name,\n",
        "                                              prediction_interpreter=None,\n",
        "                                              o_i=None,\n",
        "                                              ):\n",
        "    clf = pickle.load(open(f'cls_{cls_file_name}_{i}.p', 'rb'))\n",
        "    run_gpt2_small_on_string(string, file_name,o_i, True)\n",
        "    x = pickle.load(open(f'resid_{file_name}_{i}.p', 'rb'))\n",
        "    token_vecs = [t.detach().numpy() for t in x[0]]\n",
        "    set_1 = np.vstack(token_vecs)\n",
        "    predictions = clf.predict(set_1)\n",
        "    if prediction_interpreter:\n",
        "        predictions = [prediction_interpreter[prediction] for prediction in predictions]\n",
        "    tokens_1 = [enc.decode([j]) for j in cuda(reference_gpt2.to_tokens(string))[0]]\n",
        "    return [(a, b) for a, b in zip(tokens_1, predictions)]\n",
        "\n",
        "\n",
        "def oblate_and_run(sentence):\n",
        "    test_string = \"test_andrea\"\n",
        "    file_name = \"middle_vs_not\"\n",
        "\n",
        "\n",
        "    for layer in range(12):\n",
        "        for head_number in range(12):\n",
        "            o_i = OblationInstruction(layer, head_number)\n",
        "            origional = run_a_test_against_clf_layer_i(\n",
        "                sentence, test_string, 11, file_name,\n",
        "                prediction_interpreter={\n",
        "                    0: \"End of Sentence\",\n",
        "                    1: \"Other\",\n",
        "                }\n",
        "            )\n",
        "\n",
        "            new = oblate_and_run_a_test_against_clf_layer_i(\n",
        "                sentence, test_string, 11, file_name,\n",
        "                prediction_interpreter={\n",
        "                    0: \"End of Sentence\",\n",
        "                    1: \"Other\",\n",
        "                },\n",
        "                o_i=o_i,\n",
        "            )\n",
        "\n",
        "            if origional != new:\n",
        "                print(f'===== DIFF at Layer={layer} and head_number={head_number}')\n",
        "                print(list(zip(origional,new)))\n",
        "                print(f'<<<<<<<<<<<<Differences >>>>>>>>>>>>>>>>>>>')\n",
        "                for orig_tok, new_tok in zip(origional,new):\n",
        "                    if orig_tok != new_tok:\n",
        "                        print(f'orig={orig_tok} new={new_tok}')\n",
        "\n",
        "                print(f'%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%')\n",
        "\n",
        "\n",
        "def demo_of_end_of_sentence_vs_other(sentence, layer):\n",
        "    test_string = \"test_andrea\"\n",
        "    file_name = \"middle_vs_not\"\n",
        "    return run_a_test_against_clf_layer_i(\n",
        "        sentence, test_string, layer, file_name,\n",
        "        prediction_interpreter={\n",
        "            0: \"End of Sentence\",\n",
        "            1: \"Other\",\n",
        "        }\n",
        "    )\n",
        "\n",
        "\n",
        "def demo_of_verbing_verbs(sentence, layer):\n",
        "    test_string = \"test_andrea\"\n",
        "    file_name = \"andrea_verbing_verbs\"\n",
        "    return run_a_test_against_clf_layer_i(\n",
        "        sentence, test_string, layer, file_name,\n",
        "        prediction_interpreter={\n",
        "            0: \"Subject\",\n",
        "            1: \"Verb\",\n",
        "            2: \"Other\",\n",
        "            3: \"End of Sentence\"\n",
        "        }\n",
        "    )\n",
        "\n",
        "\n",
        "def get_undo_layer_i(file_name, i):\n",
        "    cls = pickle.load(open(f'cls_{file_name}_{i}.p', 'rb'))\n",
        "    w = cls.coef_[0]\n",
        "    w_norm = w / np.linalg.norm(w)\n",
        "    return w_norm\n",
        "\n",
        "\n",
        "def make_intervention_on_one_token(change_index, length, file_name, layer_number, multiplier):\n",
        "    w_norm = multiplier * get_undo_layer_i(file_name, layer_number)\n",
        "    array = np.zeros((1, length, 768))\n",
        "    print(f\"Intervention Shape={array.shape}\")\n",
        "    array[0, change_index, :] = w_norm\n",
        "    # print(f\"Intervention Array={array}\")\n",
        "    pickle.dump(array, open(f'w_norm{file_name}_index_{change_index}_layer_{layer_number}.p', 'wb'))\n",
        "\n",
        "\n",
        "def get_pca_vector(layer, component_number, is_absolute=False):\n",
        "    if is_absolute:\n",
        "        print(\"Aboslute\")\n",
        "        pca_vector = pickle.load(open(f'pca_files/10_token_absolute_pca_layer_{layer}_component_{component_number}.p', 'rb'))\n",
        "        return pca_vector/ np.linalg.norm(pca_vector)\n",
        "\n",
        "    pca_vector = pickle.load(open(f'pca_files/10_token_pca_layer_{layer}_component_{component_number}.p', 'rb'))\n",
        "    return pca_vector / np.linalg.norm(pca_vector)\n",
        "\n",
        "\n",
        "def reflect_vector(X, clf):\n",
        "    X = X.reshape(1, -1)  # reshape the data\n",
        "    # Calculate the distance of the point to the hyperplane\n",
        "    distance = np.abs(clf.decision_function(X)) / np.linalg.norm(clf.coef_)\n",
        "\n",
        "    # Calculate the direction to move the point\n",
        "    direction = np.sign(clf.decision_function(X))\n",
        "\n",
        "    # Reflect the point across the hyperplane\n",
        "    X_reflected = X - 2 * distance * direction * (clf.coef_ / np.linalg.norm(clf.coef_))\n",
        "\n",
        "    # Predict the classes of X and X_reflected\n",
        "    y_pred = clf.predict(X)\n",
        "    y_pred_reflected = clf.predict(X_reflected)\n",
        "\n",
        "    print(f'Predicted class for X: {y_pred[0]}')\n",
        "    print(f'Predicted class for X_reflected: {y_pred_reflected[0]}')\n",
        "\n",
        "    return X_reflected\n",
        "\n",
        "\n",
        "def run_gpt_demo_with_intervention(input_string, layer, filename, percents=[]):\n",
        "    test_tokens_in = cuda(reference_gpt2.to_tokens(input_string))\n",
        "    period_index = len(test_tokens_in[0])-1\n",
        "\n",
        "    print(f\"++++ period_index={period_index} +++++  len(tokens)={len(test_tokens_in[0])}\")\n",
        "\n",
        "    print(f\"======= REFLECTING Layer {layer}=========\")\n",
        "    my_logits = demo_gpt2(\n",
        "        test_tokens_in,\n",
        "        reflect_vector_info={\n",
        "            'layer': layer,\n",
        "            'cls': pickle.load(open(f'cls_{filename}_{layer}.p', 'rb')),\n",
        "            'token_index': period_index,\n",
        "            'array_for_size_percent': percents,\n",
        "        },\n",
        "    )\n",
        "    print_top_n_last_token_from_logits(my_logits, 5, None)\n",
        "\n",
        "    return my_logits\n",
        "\n",
        "\n",
        "def total_variation_distance(vec_p, vec_q):\n",
        "    return 0.5 * np.sum(np.abs(vec_p - vec_q))\n",
        "\n",
        "\n",
        "def get_probabilities_from_logits(my_logits):\n",
        "    # Get the logits for the last predicted token\n",
        "    last_logits = my_logits[-1, -1]\n",
        "    # Apply softmax to convert the logits to probabilities\n",
        "    probabilities = torch.nn.functional.softmax(last_logits, dim=0).detach().numpy()\n",
        "    return probabilities\n",
        "\n",
        "\n",
        "def title_compare_run_gpt2(input_string, layer):\n",
        "    test_tokens_in = cuda(reference_gpt2.to_tokens(input_string))\n",
        "    default_logits_def = demo_gpt2(test_tokens_in,)\n",
        "    intervention_logits_def = demo_gpt2(test_tokens_in, replace_layer_i_with_title_intervention=layer)\n",
        "    default_probs = get_probabilities_from_logits(default_logits_def)\n",
        "    intervention_probs = get_probabilities_from_logits(intervention_logits_def)\n",
        "\n",
        "    print('========= DEFAULT =============')\n",
        "    print_top_n_last_token_from_logits(default_logits_def, 5, None)\n",
        "\n",
        "    print(f'========= INTERVENTION LAYER {layer} =============')\n",
        "    print_top_n_last_token_from_logits(intervention_logits_def, 5, None)\n",
        "\n",
        "    print('========== TVD ==============')\n",
        "    t_v_d = total_variation_distance(default_probs, intervention_probs)\n",
        "    print(f'TVD = {t_v_d}')\n",
        "\n",
        "    return t_v_d\n",
        "\n",
        "\n",
        "def get_indexes(lst, subset):\n",
        "    return [i for i, x in enumerate(lst) if x.item() in subset]\n",
        "\n",
        "\n",
        "def run_pca_intervention_on_listed_tokens(layer, component_number, multiplier, input_string, list_of_tokens, is_absolute=False):\n",
        "    test_tokens_in = cuda(reference_gpt2.to_tokens(input_string))\n",
        "    list_of_token_indexes = [reference_gpt2.tokenizer.encode(t)[0] for t in list_of_tokens]\n",
        "    print(list_of_token_indexes)\n",
        "    index_list = get_indexes(test_tokens_in[0], list_of_token_indexes)\n",
        "    print(index_list)\n",
        "    pca_run_intervention(layer, component_number, multiplier, index_list, test_tokens_in, is_absolute=is_absolute)\n",
        "\n",
        "\n",
        "def run_pca_intervention_on_last_token(layer, component_number, multiplier, input_string, is_absolute=False):\n",
        "    test_tokens_in = cuda(reference_gpt2.to_tokens(input_string))\n",
        "    index_list = [len(test_tokens_in[0])-1,]\n",
        "    pca_run_intervention(layer, component_number, multiplier, index_list, test_tokens_in, is_absolute=is_absolute)\n",
        "\n",
        "\n",
        "def pca_run_intervention(layer, component_number, multiplier, index_list, tokens, is_absolute=False):\n",
        "    intervention_dict = {\n",
        "        'layer': layer,\n",
        "        'index_list': index_list,\n",
        "        'multiplier': multiplier,\n",
        "        'component_number': component_number,\n",
        "        'is_absolute': is_absolute,\n",
        "\n",
        "    }\n",
        "    default_logits = demo_gpt2(tokens,)\n",
        "    intervention_logits = demo_gpt2(tokens, pca_intervention_layer_and_index_list=intervention_dict)\n",
        "\n",
        "    print('========= DEFAULT =============')\n",
        "    print_top_n_last_token_from_logits(default_logits, 5, None)\n",
        "\n",
        "    print(f'========= PCA INTERVENTION Layer={layer} Component={component_number} Multiplier={multiplier} Token Indexes={index_list}=============')\n",
        "    print_top_n_last_token_from_logits(intervention_logits, 5, None)\n",
        "\n",
        "\n",
        "def titles_run_many_sentences_and_plot(list_of_sentences):\n",
        "    # Store results in a dictionary: {sentence: [tvd1, tvd2, ..., tvd12]}\n",
        "    results = {}\n",
        "    tvd_at_layer_4 = []\n",
        "\n",
        "    # Iterate over each sentence\n",
        "    for sentence in list_of_sentences:\n",
        "        print(f'[[[[[[[[[[[[[[[[[[[[[[[ {sentence} ]]]]]]]]]]]]]]]]]]]]]]]')\n",
        "        tvd_values = []\n",
        "        # For each layer\n",
        "        for layer in range(12):\n",
        "            # Calculate total variation distance\n",
        "            tvd = title_compare_run_gpt2(sentence, layer)\n",
        "            tvd_values.append(tvd)\n",
        "        results[sentence] = tvd_values\n",
        "        # Store the TVD at layer 4 for each sentence\n",
        "        tvd_at_layer_4.append((sentence, tvd_values[4]))\n",
        "\n",
        "    # Set up plot\n",
        "    plt.figure(figsize=(10, 5))\n",
        "\n",
        "    # Create a color cycle for lines\n",
        "    colors = plt.cm.viridis(np.linspace(0, 1, len(list_of_sentences)))\n",
        "\n",
        "    # Plot each sentence's results\n",
        "    for i, (sentence, tvd_values) in enumerate(results.items()):\n",
        "        plt.plot(range(12), tvd_values, label=sentence, color=colors[i])\n",
        "\n",
        "        # Set labels, title, and legend\n",
        "    plt.xlabel('Layer')\n",
        "    plt.ylabel('Total Variation Distance')\n",
        "    plt.title('Total Variation Distance by Layer for Each Sentence')\n",
        "\n",
        "    # Customizing x-axis ticks\n",
        "    plt.xticks(range(12))\n",
        "\n",
        "    # Adjusting legend position\n",
        "    plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=2)\n",
        "\n",
        "    # Show plot with legend outside of plot area\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Print the TVD at layer 4 for each sentence\n",
        "    for sentence, tvd in tvd_at_layer_4:\n",
        "        print(f'TVD at layer 4 for sentence \"{sentence}\": {tvd}')\n",
        "\n",
        "\n",
        "def demo_of_title_vs_end(sentence, layer):\n",
        "    test_string = \"test_andrea\"\n",
        "    file_name = \"title_vs_end\"\n",
        "    return run_a_test_against_clf_layer_i(\n",
        "        sentence, test_string, layer, file_name,\n",
        "        prediction_interpreter={\n",
        "            0: \"End period\",\n",
        "            1: \"Title period\",\n",
        "        }\n",
        "    )\n",
        "\n",
        "\n",
        "NEW_SENTENCE_TOKENS = [' The', ' They', '  Mr', ' Dr', ' Mrs', ' His', ' Ms', ' Miss', ' He', ' She']\n",
        "STUPID_NAMES = [' Adams']\n",
        "\n",
        "\n",
        "def run_gpt_demo_title_intervention_all_layers_and_graph(input_string):\n",
        "    filename = \"title_vs_end\"\n",
        "    new_sentence_index = [reference_gpt2.tokenizer.encode(i)[0] for i in NEW_SENTENCE_TOKENS]\n",
        "    name_index = [reference_gpt2.tokenizer.encode(i)[0] for i in STUPID_NAMES]\n",
        "\n",
        "    new_sentence_probs_all = []\n",
        "    name_probs_all = []\n",
        "    percents = []\n",
        "\n",
        "    print(\"======= DEFAULT =========\")\n",
        "    test_tokens_in = cuda(reference_gpt2.to_tokens(input_string))\n",
        "    default_logits = demo_gpt2(test_tokens_in,)\n",
        "    print_top_n_last_token_from_logits(default_logits, 5, None)\n",
        "    # Get the logits for the last predicted token\n",
        "    last_logits = default_logits[-1, -1]\n",
        "    # Apply softmax to convert the logits to probabilities\n",
        "    probabilities = torch.nn.functional.softmax(last_logits, dim=0).detach().numpy()\n",
        "    new_sentence_probs = probabilities[new_sentence_index]\n",
        "    name_probs = probabilities[name_index]\n",
        "\n",
        "    default_new_sentence_prob = new_sentence_probs.mean()\n",
        "    default_name_prob = name_probs.mean()\n",
        "\n",
        "    for layer in range(12):\n",
        "        my_logits = run_gpt_demo_with_intervention(input_string, layer, filename, percents=percents)\n",
        "        # Get the logits for the last predicted token\n",
        "        last_logits = my_logits[-1, -1]\n",
        "        # Apply softmax to convert the logits to probabilities\n",
        "        probabilities = torch.nn.functional.softmax(last_logits, dim=0).detach().numpy()\n",
        "        new_sentence_probs = probabilities[new_sentence_index]\n",
        "        name_probs = probabilities[name_index]\n",
        "\n",
        "        new_sentence_probs_all.append(new_sentence_probs.mean())\n",
        "        name_probs_all.append(name_probs.mean())\n",
        "\n",
        "    print(f\"Percents  = {percents}\")\n",
        "    # Extract layers and percents\n",
        "    layers = [layer for layer, _ in percents]\n",
        "    percent_values = [percent.item() for _, percent in percents]  # use .item() to convert tensors to numbers\n",
        "\n",
        "    # Create the plot\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(layers, percent_values, marker='o')\n",
        "    plt.xlabel('Layer')\n",
        "    plt.ylabel('Intervention Size')\n",
        "    plt.title('Intervention Size % of Residual Size by Layer')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    # Plot the average probabilities for each set of tokens at each layer\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(range(12), new_sentence_probs_all, label='New Sentence Tokens', color='blue')\n",
        "    plt.plot(range(12), name_probs_all, label=f'{STUPID_NAMES}', color='red')\n",
        "    plt.axhline(default_new_sentence_prob, color='blue', linestyle='dotted', label='Default New Sentence Prob.')\n",
        "    plt.axhline(default_name_prob, color='red', linestyle='dotted', label='Default Name Prob.')\n",
        "    plt.xlabel('Layer')\n",
        "    plt.ylabel('Average Probability')\n",
        "    plt.title(f'Average Probability by Layer for \"{input_string}\"')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    ## Prob of all things\n",
        "    # Extract layers and percents\n",
        "    layers = [layer for layer, _ in percents]\n",
        "    percent_values = [percent.item() for _, percent in percents]\n",
        "\n",
        "    fig, ax1 = plt.subplots(figsize=(10, 5))\n",
        "\n",
        "    # Plot the intervention sizes\n",
        "    ax1.plot(layers, percent_values, 'o-', color='tab:purple', label='Intervention Size', linewidth=2.5,\n",
        "             linestyle='dashed')\n",
        "    ax1.set_xlabel('Layer')\n",
        "    ax1.set_ylabel('Intervention Size', color='tab:purple')\n",
        "    ax1.tick_params(axis='y', labelcolor='tab:purple')\n",
        "\n",
        "    ax2 = ax1.twinx()  # Create a second y-axis\n",
        "\n",
        "    # Plot the probabilities on the second y-axis\n",
        "    ax2.plot(layers, new_sentence_probs_all, 's-', label='New Sentence Tokens', color='tab:orange')\n",
        "    ax2.plot(layers, name_probs_all, 'd-', label=f'{STUPID_NAMES}', color='tab:green')\n",
        "    ax2.axhline(default_new_sentence_prob, color='tab:orange', linestyle='dotted', label='Default New Sentence Prob.')\n",
        "    ax2.axhline(default_name_prob, color='tab:green', linestyle='dotted', label='Default Name Prob.')\n",
        "    ax2.set_ylabel('Average Probability', color='tab:orange')\n",
        "    ax2.tick_params(axis='y', labelcolor='tab:orange')\n",
        "\n",
        "    # Add explanations to the legend\n",
        "    intervention_line = mlines.Line2D([], [], color='tab:purple', marker='o', linestyle='dashed',\n",
        "                                      label='Intervention Size')\n",
        "    left_label = mlines.Line2D([], [], color='white', label='Left: Intervention Size')\n",
        "    right_label = mlines.Line2D([], [], color='white', label='Right: Average Probability')\n",
        "    ax2.legend(handles=[intervention_line, ax2.get_legend_handles_labels()[0][0], ax2.get_legend_handles_labels()[0][1],\n",
        "                        ax2.get_legend_handles_labels()[0][2], ax2.get_legend_handles_labels()[0][3], left_label,\n",
        "                        right_label])\n",
        "\n",
        "    fig.subplots_adjust(top=0.9)  # Adjust the top space\n",
        "    fig.suptitle(f'Intervention Sizes and Probabilities by Layer for \"{input_string}\"',\n",
        "                 y=0.98)  # Adjust the position of title\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "IPython.embed()\n"
      ],
      "metadata": {
        "id": "p7dvWAcY7HBZ",
        "outputId": "5c87bb7d-afe1-437c-c099-1b0d11822a67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using pad_token, but it is not set yet.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained model gpt2-small into HookedTransformer\n",
            "Python 3.10.12 (main, Jun  7 2023, 12:45:35) [GCC 9.4.0]\n",
            "Type 'copyright', 'credits' or 'license' for more information\n",
            "IPython 7.34.0 -- An enhanced Interactive Python. Type '?' for help.\n",
            "\n",
            "In [1]: demo_of_subject_end_of_sentence_other(\" My name is Dr. Lincoln. \", 11)\n",
            "---------------------------------------------------------------------------\n",
            "FileNotFoundError                         Traceback (most recent call last)\n",
            "<ipython-input-1-2d3855a6dee6> in <cell line: 1>()\n",
            "----> 1 demo_of_subject_end_of_sentence_other(\" My name is Dr. Lincoln. \", 11)\n",
            "\n",
            "<ipython-input-15-9f3ea602009e> in demo_of_subject_end_of_sentence_other(sentence, layer)\n",
            "    456     test_string = \"test_andrea\"\n",
            "    457     file_name = \"split_token_by_lists_test_subject\"\n",
            "--> 458     return run_a_test_against_clf_layer_i(\n",
            "    459         sentence, test_string, layer, file_name,\n",
            "    460         prediction_interpreter={\n",
            "\n",
            "<ipython-input-15-9f3ea602009e> in run_a_test_against_clf_layer_i(string, file_name, layer, cls_file_name, prediction_interpreter)\n",
            "    441 # Run a test to see how the classifier works\n",
            "    442 def run_a_test_against_clf_layer_i(string, file_name, layer, cls_file_name, prediction_interpreter=None):\n",
            "--> 443     clf = pickle.load(open(f'cls_{cls_file_name}_{layer}.p', 'rb'))\n",
            "    444     run_gpt2_small_on_string(string, file_name)\n",
            "    445     x = pickle.load(open(f'resid_{file_name}_{layer}.p', 'rb'))\n",
            "\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'cls_split_token_by_lists_test_subject_11.p'\n",
            "\n",
            "In [2]: run_gpt2_small_on_string(\" My name is \", \"test-andrea\")\n",
            "---------------------------------------------------------------------------\n",
            "RuntimeError                              Traceback (most recent call last)\n",
            "<ipython-input-2-da35de4bbe2b> in <cell line: 1>()\n",
            "----> 1 run_gpt2_small_on_string(\" My name is \", \"test-andrea\")\n",
            "\n",
            "<ipython-input-15-9f3ea602009e> in run_gpt2_small_on_string(input_string, prefix, o_i, print_logits)\n",
            "    432     end_of_sentence_tokens = [30, 13, 0]\n",
            "    433     end_of_sentence_indicies = [ind for ind, ele in enumerate(test_tokens_in[0]) if ele.item() in end_of_sentence_tokens]\n",
            "--> 434     demo_logits_def = demo_gpt2(test_tokens_in, save_with_prefix=prefix, o_i=o_i)\n",
            "    435     if print_logits:\n",
            "    436         print_top_n_last_token_from_logits(demo_logits_def, 5, None)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py in _call_impl(self, *args, **kwargs)\n",
            "   1499                 or _global_backward_pre_hooks or _global_backward_hooks\n",
            "   1500                 or _global_forward_hooks or _global_forward_pre_hooks):\n",
            "-> 1501             return forward_call(*args, **kwargs)\n",
            "   1502         # Do not call functions when jit is used\n",
            "   1503         full_backward_hooks, non_full_backward_hooks = [], []\n",
            "\n",
            "<ipython-input-15-9f3ea602009e> in forward(self, tokens, save_with_prefix, load, load_with_mod_vector, intervene_in_resid_at_layer, resid_intervention_filename, save_tokens_at_index, split_tokens_by_lists, split_tokens_by_lists_filename, reflect_vector_info, o_i, index_lists_with_output_lists, store_index_diffs, replace_layer_i_with_title_intervention, pca_intervention_layer_and_index_list)\n",
            "    280                 residual = residual + load_with_mod_vector\n",
            "    281         else:\n",
            "--> 282             embed = self.embed(tokens)\n",
            "    283             pos_embed = self.pos_embed(tokens)\n",
            "    284             residual = embed + pos_embed\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py in _call_impl(self, *args, **kwargs)\n",
            "   1499                 or _global_backward_pre_hooks or _global_backward_hooks\n",
            "   1500                 or _global_forward_hooks or _global_forward_pre_hooks):\n",
            "-> 1501             return forward_call(*args, **kwargs)\n",
            "   1502         # Do not call functions when jit is used\n",
            "   1503         full_backward_hooks, non_full_backward_hooks = [], []\n",
            "\n",
            "<ipython-input-15-9f3ea602009e> in forward(self, tokens)\n",
            "     97         # tokens: [batch, position]\n",
            "     98         if self.cfg.debug: print(\"Tokens:\", tokens.shape)\n",
            "---> 99         embed = self.W_E[tokens, :]  # [batch, position, d_model]\n",
            "    100         # visualize_tensor(self.W_E, 'WE')\n",
            "    101         if self.cfg.debug: print(\"Embeddings:\", embed.shape)\n",
            "\n",
            "RuntimeError: indices should be either on cpu or on the same device as the indexed tensor (cpu)\n",
            "\n",
            "In [3]: \u0004\n",
            "Do you really want to exit ([y]/n)? \n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.14"
    },
    "vscode": {
      "interpreter": {
        "hash": "eb812820b5094695c8a581672e17220e30dd2c15d704c018326e3cc2e1a566f1"
      }
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a84e4b105f7240c683f831cb49020a56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d89e5aa9b9494acf8e62d12cdb1cddea",
              "IPY_MODEL_c28a33e923ab4fbb863bd76e9517fccb",
              "IPY_MODEL_2f1f75b982814d7497316b47e0fa537d"
            ],
            "layout": "IPY_MODEL_d3e721d768494315b9dc2fa1268d6b45"
          }
        },
        "d89e5aa9b9494acf8e62d12cdb1cddea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0be8731903a64845a63ff46f54e065c6",
            "placeholder": "​",
            "style": "IPY_MODEL_1897b1ff2ba84e69905f40f9c47cafe7",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "c28a33e923ab4fbb863bd76e9517fccb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e37eb8309d54502a3d7169e30501e5a",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0752b803614445c2970371992930d85d",
            "value": 665
          }
        },
        "2f1f75b982814d7497316b47e0fa537d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_794172797dc543fbbe4536d8b849fbf6",
            "placeholder": "​",
            "style": "IPY_MODEL_7da2c357e1b74ebf80abf19471269d12",
            "value": " 665/665 [00:00&lt;00:00, 36.3kB/s]"
          }
        },
        "d3e721d768494315b9dc2fa1268d6b45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0be8731903a64845a63ff46f54e065c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1897b1ff2ba84e69905f40f9c47cafe7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e37eb8309d54502a3d7169e30501e5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0752b803614445c2970371992930d85d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "794172797dc543fbbe4536d8b849fbf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7da2c357e1b74ebf80abf19471269d12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7e55462b5eb4da0b9babab9a18727bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2c39eff701764f1199f2a6a2e676edcf",
              "IPY_MODEL_c5eeccdae2cb4e9394eec4545faa9571",
              "IPY_MODEL_fd9b7e79adf94b1fa518e97747d67180"
            ],
            "layout": "IPY_MODEL_46037b01da29484eb019b7771387611d"
          }
        },
        "2c39eff701764f1199f2a6a2e676edcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54c16adb46304a55baf9ac87368cf598",
            "placeholder": "​",
            "style": "IPY_MODEL_1b1ebc1f9cf5486ca3f86a4a8fba1ef9",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "c5eeccdae2cb4e9394eec4545faa9571": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6aee52c665ed418d8af75fabd9c80434",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b81b83c3670d4a8698a8a1daa056a7e9",
            "value": 548105171
          }
        },
        "fd9b7e79adf94b1fa518e97747d67180": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b44ae51aadf54ada8a47b6bc76828e48",
            "placeholder": "​",
            "style": "IPY_MODEL_7e1cf1fe90bf401d96ca4c0da4c35cd4",
            "value": " 548M/548M [00:05&lt;00:00, 194MB/s]"
          }
        },
        "46037b01da29484eb019b7771387611d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54c16adb46304a55baf9ac87368cf598": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b1ebc1f9cf5486ca3f86a4a8fba1ef9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6aee52c665ed418d8af75fabd9c80434": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b81b83c3670d4a8698a8a1daa056a7e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b44ae51aadf54ada8a47b6bc76828e48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e1cf1fe90bf401d96ca4c0da4c35cd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ee89d75315041d2890d0179210101cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aef7fc32abea4b598c3bbdc530524c1d",
              "IPY_MODEL_2bb742f2b01a482d823e5b8769c9f853",
              "IPY_MODEL_954aca4c5b014c749b63e75cd9c215c0"
            ],
            "layout": "IPY_MODEL_5266a7eeb57244d081d180eb58db8017"
          }
        },
        "aef7fc32abea4b598c3bbdc530524c1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d45b2f6294c450aa8fabdda1eaf82ad",
            "placeholder": "​",
            "style": "IPY_MODEL_4119255fd7ea4662aed35ab1ae7d5272",
            "value": "Downloading (…)neration_config.json: 100%"
          }
        },
        "2bb742f2b01a482d823e5b8769c9f853": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97ec2c35f4ef4cfcb77a2465dd9e8828",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0297bcaaefbb4f58bdabd171bc0749d8",
            "value": 124
          }
        },
        "954aca4c5b014c749b63e75cd9c215c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e18eb8e96d214325b37c6bdee56b41fe",
            "placeholder": "​",
            "style": "IPY_MODEL_14f6bdf701dc4099a911b41ea707b3c6",
            "value": " 124/124 [00:00&lt;00:00, 7.10kB/s]"
          }
        },
        "5266a7eeb57244d081d180eb58db8017": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d45b2f6294c450aa8fabdda1eaf82ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4119255fd7ea4662aed35ab1ae7d5272": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97ec2c35f4ef4cfcb77a2465dd9e8828": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0297bcaaefbb4f58bdabd171bc0749d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e18eb8e96d214325b37c6bdee56b41fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14f6bdf701dc4099a911b41ea707b3c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3bc6578e54f40cea1516b51b5afec64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6c03fc86cdca48eb98a293b472e8465b",
              "IPY_MODEL_5059f5bef2ec4c00b798ceaa3c94d3c8",
              "IPY_MODEL_a22c234ed2aa44c79e5888079598b7d8"
            ],
            "layout": "IPY_MODEL_9a182cc64a2d4f24b7e0643db120383b"
          }
        },
        "6c03fc86cdca48eb98a293b472e8465b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d564c82253854017bfc2f9d416c61bf3",
            "placeholder": "​",
            "style": "IPY_MODEL_fc9e72c7580d4526af5288fbd4d4069f",
            "value": "Downloading (…)olve/main/vocab.json: 100%"
          }
        },
        "5059f5bef2ec4c00b798ceaa3c94d3c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f045d93988d84766a3e430a9988d954d",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_57758202d2a04157a331ec629e6ec9e3",
            "value": 1042301
          }
        },
        "a22c234ed2aa44c79e5888079598b7d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ca35e387c85459b9f841e7fd3015a33",
            "placeholder": "​",
            "style": "IPY_MODEL_ffe93005711e4820a3e79b0f41fe243d",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 3.08MB/s]"
          }
        },
        "9a182cc64a2d4f24b7e0643db120383b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d564c82253854017bfc2f9d416c61bf3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc9e72c7580d4526af5288fbd4d4069f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f045d93988d84766a3e430a9988d954d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57758202d2a04157a331ec629e6ec9e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3ca35e387c85459b9f841e7fd3015a33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffe93005711e4820a3e79b0f41fe243d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb0839d3abce489fb4baabda852584da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cee525e248b54f06ab89e2863bb117d0",
              "IPY_MODEL_44c36481157f4cd6890f496b6e059e9f",
              "IPY_MODEL_5729560342e546d48bcde49ad8d0569f"
            ],
            "layout": "IPY_MODEL_84c1001000f943c2b32abd280e686204"
          }
        },
        "cee525e248b54f06ab89e2863bb117d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b9e091bb46b415dba916ecf20e1850c",
            "placeholder": "​",
            "style": "IPY_MODEL_18268faf2748435da147f71eb1555316",
            "value": "Downloading (…)olve/main/merges.txt: 100%"
          }
        },
        "44c36481157f4cd6890f496b6e059e9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e7eaa0c21714867857d7eb90c47976c",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cfe52ec68cfb46d89fde26f3c2fc45ca",
            "value": 456318
          }
        },
        "5729560342e546d48bcde49ad8d0569f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5fb4482c5837496caf72c008a78a15e0",
            "placeholder": "​",
            "style": "IPY_MODEL_98ff50465e054ac29ee08e02a527dbea",
            "value": " 456k/456k [00:00&lt;00:00, 28.1MB/s]"
          }
        },
        "84c1001000f943c2b32abd280e686204": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b9e091bb46b415dba916ecf20e1850c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18268faf2748435da147f71eb1555316": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e7eaa0c21714867857d7eb90c47976c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfe52ec68cfb46d89fde26f3c2fc45ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5fb4482c5837496caf72c008a78a15e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98ff50465e054ac29ee08e02a527dbea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3b0ba3dece840a19770d8e2b78d6123": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_04ebdc3fcdb74e8bbaf63024d8e4ae14",
              "IPY_MODEL_0eaa83c6a62648a0b6d5d8a9c61d5e58",
              "IPY_MODEL_c06fa45bfcf94c52a47a6252b9fee05f"
            ],
            "layout": "IPY_MODEL_23428c96d9e34f0ea75d06fbefd2a41e"
          }
        },
        "04ebdc3fcdb74e8bbaf63024d8e4ae14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4d9b74c63c84474a1900b4690868b8b",
            "placeholder": "​",
            "style": "IPY_MODEL_54aed3ddaec441f6905d12cb5fc1770a",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "0eaa83c6a62648a0b6d5d8a9c61d5e58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a52bb728d4c4dbc8d843868fd50d6a9",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4242ea29288d4664a77f8a8ef4fa7095",
            "value": 1355256
          }
        },
        "c06fa45bfcf94c52a47a6252b9fee05f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d3a91a94c5c4005b71f24c8e9684b97",
            "placeholder": "​",
            "style": "IPY_MODEL_ec3d86915cbf44ccba658b5b789ae9ff",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 16.3MB/s]"
          }
        },
        "23428c96d9e34f0ea75d06fbefd2a41e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4d9b74c63c84474a1900b4690868b8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54aed3ddaec441f6905d12cb5fc1770a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a52bb728d4c4dbc8d843868fd50d6a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4242ea29288d4664a77f8a8ef4fa7095": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1d3a91a94c5c4005b71f24c8e9684b97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec3d86915cbf44ccba658b5b789ae9ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}